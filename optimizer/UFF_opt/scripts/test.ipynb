{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning on use of the timeseries module: If the inherent timescales of the system are long compared to those being analyzed, this statistical inefficiency may be an underestimate.  The estimate presumes the use of many statistically independent samples.  Tests should be performed to assess whether this condition is satisfied.   Be cautious in the interpretation of the data.\n"
     ]
    }
   ],
   "source": [
    "# These package is inherited from Lenard-Jones optimization part of DMFF\n",
    "\n",
    "import openmm.app as app\n",
    "import openmm as mm\n",
    "import openmm.unit as unit\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import dmff\n",
    "from dmff.api.xmlio import XMLIO\n",
    "from dmff.api.paramset import ParamSet\n",
    "from dmff.generators.classical import CoulombGenerator, LennardJonesGenerator\n",
    "from dmff.api.hamiltonian import Hamiltonian\n",
    "from dmff.operators import ParmedLennardJonesOperator\n",
    "from dmff import NeighborListFreud\n",
    "from dmff.mbar import ReweightEstimator\n",
    "import mdtraj as md\n",
    "from tqdm import tqdm, trange\n",
    "import parmed\n",
    "import sys\n",
    "import os\n",
    "from dmff.api.topology import DMFFTopology\n",
    "# this is a package I write to solve some IO problems utils.py\n",
    "from utils import create_supercell, gas_generate,add_loading, simple_merge\n",
    "from utils import cutoff_topology\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "from utils import extract_from_raspa\n",
    "from jax import clear_backends, clear_caches\n",
    "import threading\n",
    "\"\"\"\n",
    "\n",
    "Superparameters for Lenard-Jone Potential optimization\n",
    "\n",
    "\"\"\"\n",
    "Number_points = 5            ## must be smaller than len(picked_ls)\n",
    "Trajectory_length = 250#250          #液体pdb文件的个数\n",
    "target_site1 = -50.60                  #拟合的目标binding energy\n",
    "target_site2 = -46.69           #拟合的目标binding energy\n",
    "SET_temperature=  100           #温度设定\n",
    "time_gap=   2.2                      #分子动力学模拟过程中每一个frame的时间间隔，单位是皮秒picosecond   推荐2-4ps\n",
    "loop_time =   100                  #迭代循环次数    推荐50-100\n",
    "scaling_factors = (3,3,2)\n",
    "cutoff = 0.905 #1.3 # unit is nanometer\n",
    "\n",
    "Transfer_unit = 2.7719416667/5.6100437023 \n",
    "\n",
    "\n",
    "\n",
    "pressure_list = [\n",
    "            0.021648873072361,\n",
    "            0.038256227758007,\n",
    "            0.059015421115065,\n",
    "            0.077698695136418,\n",
    "            0.09638196915777,\n",
    "            0.14827995255042,\n",
    "            0.20017793594306,\n",
    "            0.24584816132859,\n",
    "            0.29774614472123,\n",
    "            0.34756820877817,\n",
    "            0.39739027283511,\n",
    "            0.44928825622776,\n",
    "            0.49495848161329,\n",
    "            0.60083036773428,\n",
    "            0.69839857651246,\n",
    "            0.80219454329775,\n",
    "            0.90183867141163,\n",
    "            0.99733096085409,\n",
    "            1.1986951364176,\n",
    "            1.3959074733096,\n",
    "            1.5993475682088,\n",
    "            1.7986358244365,\n",
    "            2.0020759193357\n",
    "        ]\n",
    "\n",
    "arr_3 = np.loadtxt(\"/home/yutao/dataset/exp_303.txt\", delimiter=',')\n",
    "\n",
    "\n",
    "picked_ls = [0,1,2,3,4]#[0, 3, 6]#[0, 3, 6, 9, 12, 15, 18]   # this value need to be consistent with Number_points\n",
    "picked_pressure = [pressure_list[i] for i in picked_ls]\n",
    "picked_isotherm = [arr_3[i,1]*Transfer_unit for i in picked_ls]\n",
    "\n",
    "def is_close_to_list(value, value_list):\n",
    "    for list_value in value_list:\n",
    "        relative_error = abs((value - list_value) / list_value)\n",
    "        if relative_error < 0.01:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from utils import scaling_gas, extract_from_raspa, write_scaling_gas\n",
    "bar = 10**5\n",
    "def move_traj(dest_path = \"/home/yutao/project/MIL-120/traj0/\",picked_pressure=picked_pressure):\n",
    "    traj_ls = os.listdir(dest_path)\n",
    "    isotherm_data = [[],[]] # the first list is for pressure, the second is for loading\n",
    "    jdx = 0 \n",
    "    for traj in extract_from_raspa(traj_ls):\n",
    "        pdb_file = traj[1]\n",
    "        if not pdb_file.endswith(\".pdb\") or 'Movie_framework' not in pdb_file:\n",
    "            continue\n",
    "        if not is_close_to_list(float(traj[0])/bar, picked_pressure):\n",
    "            continue\n",
    "        isotherm_data[0].append(float(traj[0])/bar)\n",
    "        pdb_path = os.path.join(dest_path, pdb_file)\n",
    "        with open(pdb_path) as f:\n",
    "            lines = f.readlines()\n",
    "        num_atoms_list = []  # List to store the number of atoms in each structure\n",
    "        index = 0\n",
    "        write_idx = 1\n",
    "        num_atoms = 0  # Variable to store the number of atoms in the current structure\n",
    "        directory = f\"./traj/{jdx+1}\"\n",
    "        jdx += 1\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            print(\"Directory created:\", directory)\n",
    "        for line in lines:\n",
    "            if line.startswith(\"MODEL\"):\n",
    "                if index>=150:\n",
    "                    write_scaling_gas(block_coords, \"data/gas.pdb\", write_idx, dest_path=directory)\n",
    "                    write_idx += 1\n",
    "                block_coords = []\n",
    "                block_Csym = []\n",
    "                index += 1\n",
    "                num_atoms_list.append(num_atoms)  # Add the number of atoms to the list\n",
    "                num_atoms = 0  # Reset the number of atoms for the next structure\n",
    "            if line.startswith(\"ATOM\"):\n",
    "                parts = line.split()\n",
    "                coords = np.array([float(parts[4]), float(parts[5]), float(parts[6])])\n",
    "                block_coords.append(coords)\n",
    "                block_Csym.append(parts[-1])\n",
    "                num_atoms += 1  # Increment the number of atoms\n",
    "        #num_atoms_list.append(num_atoms)  # Add the number of atoms for the last structure\n",
    "        #   isotherm_data[1].append(sum(num_atoms_list)/len(num_atoms_list)/3/3/2/3)\n",
    "        #print(\"Number of atoms in each structure for\", pdb_file, \":\", num_atoms_list)\n",
    "    #return isotherm_data\n",
    "\n",
    "def update_mask(parameters, mask):\n",
    "    updated_parameters = parameters.copy()\n",
    "    \n",
    "    for force_type, force_params in mask.items():\n",
    "        if force_type in parameters:\n",
    "            for param, mask_array in force_params.items():\n",
    "                if param in parameters[force_type]:\n",
    "                    # Update values based on the mask\n",
    "                    updated_parameters[force_type][param] = jnp.where(mask_array == 1, \n",
    "                                                                      parameters[force_type][param], \n",
    "                                                                      0)\n",
    "    return updated_parameters\n",
    "\n",
    "def compute_binding_energy(paramset,topo, pos, lj_gen, numframe=720,cutoff=cutoff):\n",
    "    topodata = dmff.DMFFTopology(topo)\n",
    "    # Because dmfftopology does not provide a good entry for open.topology object generated by pdb file, I had to suplement something\n",
    "    for atom in topodata.atoms():\n",
    "        if atom.residue.name==\"MOL\":\n",
    "            atom.meta['type']=atom.meta['element']\n",
    "            atom.meta['class']=atom.meta['element']\n",
    "        elif atom.residue.name==\"GAS\":\n",
    "            #print(atom.meta)\n",
    "            atom.meta['type']=atom.meta['element']+\"_co2\"\n",
    "            atom.meta['class']=atom.meta['element']+\"_co2\"\n",
    "        #print(atom.meta['element'])\n",
    "    cov_mat = topodata.buildCovMat()\n",
    "    lj_force = lj_gen.createPotential(\n",
    "    topodata, nonbondedMethod=app.PME, nonbondedCutoff=cutoff, args={})\n",
    "    pos_jnp = jnp.array(pos.value_in_unit(unit.nanometer))\n",
    "    cell_jnp = jnp.array(topo.getPeriodicBoxVectors().value_in_unit(unit.nanometer))\n",
    "    cov_mat=cov_mat.at[:numframe,:numframe].set(1)\n",
    "    nblist = NeighborListFreud(topo.getPeriodicBoxVectors().value_in_unit(unit.nanometer), cutoff, cov_mat)\n",
    "    nblist.allocate(pos_jnp, cell_jnp)\n",
    "    pairs = jnp.array(nblist.pairs)\n",
    "    ener = lj_force(pos_jnp,cell_jnp, pairs, paramset)\n",
    "    return ener\n",
    "\n",
    "def analyse_traj(paramset, lj_gen, dest_path = \"./traj/\", interval=10):\n",
    "    global picked_isotherm, picked_pressure\n",
    "    traj_dict = {}\n",
    "    global Number_points, Trajectory_length, cutoff\n",
    "    traj_ls = os.listdir(dest_path)\n",
    "    create_supercell(\"data/MIL-120.pdb\", scaling_factors, \"scaled_frame.pdb\")\n",
    "\n",
    "    # Filter out file names and keep only directory names\n",
    "    dir_names = [name for name in traj_ls if os.path.isdir(os.path.join(dest_path, name)) and name.isdigit()]\n",
    "    dir_names = sorted(map(int, dir_names))\n",
    "    dir_names = [str(i) for i in dir_names]\n",
    "    for directory in dir_names[:Number_points]:\n",
    "        idx = int(directory)\n",
    "        traj_dict[idx] = {'experiment': {'pressure': picked_pressure[idx-1], 'loading': picked_isotherm[idx-1]}, 'structure': [], 'refer_energy':[], 'loading':[]}\n",
    "        gas_dir = os.path.join(dest_path, directory)\n",
    "        for gas_path in os.listdir(gas_dir)[::interval]:\n",
    "            topo, pos, num = simple_merge(\"scaled_frame.pdb\",os.path.join(gas_dir,gas_path))\n",
    "            ener_lj = compute_binding_energy(paramset,topo, pos, lj_gen, numframe=720,cutoff=cutoff)\n",
    "            traj_dict[idx]['structure'].append([topo, pos])\n",
    "            traj_dict[idx]['loading'].append(num/scaling_factors[0]/scaling_factors[1]/scaling_factors[2]/3)\n",
    "            traj_dict[idx]['refer_energy'].append(ener_lj)\n",
    "    clear_backends()    \n",
    "    for key in traj_dict.keys():\n",
    "        traj_dict[key]['refer_energy'] = jnp.array(traj_dict[key]['refer_energy'])\n",
    "        traj_dict[key]['loading'] = jnp.array(traj_dict[key]['loading'])\n",
    "        traj_dict[key]['estimator'] = ReweightEstimator(ref_energies=traj_dict[key]['refer_energy'], temperature=SET_temperature)\n",
    "    return traj_dict\n",
    "\n",
    "import subprocess\n",
    "def sample(cmd=\"/home/yutao/project/aiida/applications/sample.sh\"):\n",
    "    command = [cmd]\n",
    "    # Run the script using subprocess\n",
    "    completed_process = subprocess.run(command, capture_output=True, cwd=\"/home/yutao/project/aiida/applications\",text=True)\n",
    "\n",
    "    # Check the return code\n",
    "    if completed_process.returncode == 0:\n",
    "        # The script finished successfully\n",
    "        print(\"Script finished successfully!\")\n",
    "        # Display the output in the notebook\n",
    "        print(\"Script output:\")\n",
    "        print(completed_process.stdout)\n",
    "        # Continue with your program logic here\n",
    "    else:\n",
    "        # The script encountered an error\n",
    "        print(\"Script encountered an error:\", completed_process.stderr)\n",
    "        print(\"Script encountered an error:\", completed_process.stderr)\n",
    "        # Handle the error or exit the program\n",
    "\n",
    "def detect_parameter_change(paramset_new, paramset_old):\n",
    "    # Get the initial parameters\n",
    "    initial_sigma = paramset_old.parameters['LennardJonesForce']['sigma']\n",
    "    initial_epsilon = paramset_old.parameters['LennardJonesForce']['epsilon']\n",
    "    \n",
    "    # Get the updated parameters\n",
    "    updated_sigma = paramset_new.parameters['LennardJonesForce']['sigma']\n",
    "    updated_epsilon = paramset_new.parameters['LennardJonesForce']['epsilon']\n",
    "    \n",
    "    # Calculate the percentage change for each parameter\n",
    "    sigma_change = np.abs(updated_sigma - initial_sigma) / initial_sigma\n",
    "    epsilon_change = np.abs(updated_epsilon - initial_epsilon) / initial_epsilon\n",
    "\n",
    "    # Find the indices of values that have changed by more than 40%\n",
    "    sigma_indices = np.where(sigma_change > 0.4)[0]\n",
    "    epsilon_indices = np.where(epsilon_change > 0.4)[0]\n",
    "    \n",
    "    return sigma_indices, epsilon_indices\n",
    "\n",
    "def fix_changed_parameters(paramset, sigma_indices, epsilon_indices):\n",
    "    for idx in sigma_indices:\n",
    "        paramset.mask['LennardJonesForce']['sigma'] = paramset.mask['LennardJonesForce']['sigma'].at[idx].set(0)\n",
    "    for idx in epsilon_indices:\n",
    "        if idx==0:continue\n",
    "        paramset.mask['LennardJonesForce']['epsilon'] = paramset.mask['LennardJonesForce']['epsilon'].at[idx].set(0)\n",
    "    return paramset\n",
    "\n",
    "import json\n",
    "Transfer_energy_unit = 254.152/2.11525\n",
    "Transfer_length_unit = 10\n",
    "def update_ff(paramset, dest_path='/home/yutao/project/aiida/applications/ff_1.json'):\n",
    "    global Transfer_energy_unit, Transfer_length_unit\n",
    "    element_list = ['Al_', 'C_', 'H_', 'O_']\n",
    "    params = paramset.parameters\n",
    "    ff_data = {}\n",
    "    if len(element_list) != params['LennardJonesForce']['sigma'].shape[0]-2:\n",
    "        raise ValueError(\"Length of element list and parameter list does not match\")\n",
    "    sigma_list = params['LennardJonesForce']['sigma'].tolist()\n",
    "    epsilon_list = params['LennardJonesForce']['epsilon'].tolist()\n",
    "    for idx in range(len(element_list)):\n",
    "        ff_data[element_list[idx]] = ['lennard-jones', epsilon_list[idx]*Transfer_energy_unit, sigma_list[idx]*Transfer_length_unit]\n",
    "    with open(dest_path, 'w') as f:\n",
    "        json.dump(ff_data, f, indent=4)\n",
    "\n",
    "def show_ff(file_path='/home/yutao/project/aiida/applications/ff_1.json'):\n",
    "    global Transfer_energy_unit, Transfer_length_unit\n",
    "    element_list = ['Al_', 'C_', 'H_', 'O_']\n",
    "    ff_data = json.load(open(file_path))\n",
    "\n",
    "    for idx in range(len(element_list)):\n",
    "        print(ff_data[element_list[idx]][0],ff_data[element_list[idx]][1]/Transfer_energy_unit,ff_data[element_list[idx]][2]/Transfer_length_unit)\n",
    "#update_ff(paramset)\n",
    "        \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "The actutaly optimization part starts here\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "#If the code is not restarted, I use these codes\n",
    "\n",
    "# Initial Optimized parameters\n",
    "xmlio = XMLIO()\n",
    "xmlio.loadXML(\"data/init.xml\")\n",
    "ffinfo = xmlio.parseXML()\n",
    "paramset = ParamSet()\n",
    "lj_gen = LennardJonesGenerator(ffinfo, paramset)\n",
    "\n",
    "xmlio = XMLIO()\n",
    "xmlio.loadXML(\"data/init.xml\")\n",
    "ffinfo = xmlio.parseXML()\n",
    "paramset_old = ParamSet()\n",
    "lj_gen = LennardJonesGenerator(ffinfo, paramset_old)\n",
    "\n",
    "paramset.mask['LennardJonesForce']['sigma'] = paramset.mask['LennardJonesForce']['sigma'].at[0].set(0)\n",
    "paramset.mask['LennardJonesForce']['sigma'] = paramset.mask['LennardJonesForce']['sigma'].at[1].set(0)\n",
    "paramset.mask['LennardJonesForce']['sigma'] = paramset.mask['LennardJonesForce']['sigma'].at[2].set(0)\n",
    "paramset.mask['LennardJonesForce']['sigma'] = paramset.mask['LennardJonesForce']['sigma'].at[3].set(0)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Initial Optimized parameters\n",
    "xmlio = XMLIO()\n",
    "xmlio.loadXML(\"data/init.xml\")\n",
    "ffinfo = xmlio.parseXML()\n",
    "paramset_old = ParamSet()\n",
    "lj_gen = LennardJonesGenerator(ffinfo, paramset_old)\n",
    "\n",
    "xmlio = XMLIO()\n",
    "xmlio.loadXML(\"data/init.xml\")\n",
    "#xmlio.loadXML(\"0219.xml\")\n",
    "ffinfo = xmlio.parseXML()\n",
    "paramset = ParamSet()\n",
    "lj_gen = LennardJonesGenerator(ffinfo, paramset)\n",
    "\n",
    "\n",
    "paramset.mask['LennardJonesForce']['sigma'] = paramset.mask['LennardJonesForce']['sigma'].at[0].set(0)\n",
    "paramset.mask['LennardJonesForce']['sigma'] = paramset.mask['LennardJonesForce']['sigma'].at[1].set(0)\n",
    "paramset.mask['LennardJonesForce']['sigma'] = paramset.mask['LennardJonesForce']['sigma'].at[2].set(0)\n",
    "paramset.mask['LennardJonesForce']['sigma'] = paramset.mask['LennardJonesForce']['sigma'].at[3].set(0)\n",
    "\n",
    "#paramset.mask['LennardJonesForce']['epsilon'] = paramset.mask['LennardJonesForce']['epsilon'].at[1].set(0)\n",
    "\n",
    "optimizer = optax.adam(0.02)\n",
    "opt_state = optimizer.init(paramset)\n",
    "\n",
    "scalar_epsilon = paramset_old.parameters['LennardJonesForce']['epsilon']\n",
    "scalar_epsilon = scalar_epsilon/jnp.max(scalar_epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story starts\n",
      "Once starts\n",
      "Successfully update once\n",
      "This is 0th time  Loss: 6.571977550590255 and Parameters:  [0.40082 0.34309 0.25711 0.31181 0.305   0.28   ] [2.07525 0.39979 0.22436 0.21079 0.65757 0.22469]\n",
      "Once starts\n",
      "Successfully update once\n",
      "This is 1th time  Loss: 6.571977550590255 and Parameters:  [0.40082 0.34309 0.25711 0.31181 0.305   0.28   ] [2.0352405  0.35975167 0.2642098  0.1707372  0.65757    0.22469   ]\n",
      "Once starts\n",
      "Successfully update once\n",
      "This is 2th time  Loss: 6.571977550590255 and Parameters:  [0.40082 0.34309 0.25711 0.31181 0.305   0.28   ] [1.99521496 0.31964572 0.2642098  0.13059379 0.65757    0.22469   ]\n"
     ]
    }
   ],
   "source": [
    "os.system(\"cp /home/yutao/project/aiida/applications/UFF.json /home/yutao/project/aiida/applications/ff_1.json\")\n",
    "#os.system(\"cp 0219.json /home/yutao/project/aiida/applications/ff_1.json\")\n",
    "print(\"Story starts\")\n",
    "for nloop in range(3):\n",
    "    '''\n",
    "    t = threading.Thread(target=sample, args=(\"/home/yutao/project/aiida/applications/sample.sh\",))\n",
    "    t.start()\n",
    "    # Wait for 2 hours for the function to complete\n",
    "    t.join(45*60)  # Timeout in seconds# If the function is still running after 2 hours, continue with the rest of the code\n",
    "    if t.is_alive():\n",
    "        print(\"Function 'sample' is still running after 50 mins, skipping it and continuing with the rest of the code.\")\n",
    "    else:\n",
    "        print(\"Function 'sample' completed within 50 mins.\")\n",
    "    print(\"start derivative\")\n",
    "    '''\n",
    "    print(\"Once starts\")\n",
    "    #sample(\"/home/yutao/project/aiida/applications/sample.sh\")\n",
    "    #move_traj(dest_path=\"/home/yutao/project/MIL-120/traj0/\",picked_pressure=picked_pressure)\n",
    "    traj_dict = analyse_traj(paramset, lj_gen,interval=100)\n",
    "\n",
    "    def loss(paramset):\n",
    "        errors = []\n",
    "        for idx in range(1, Number_points+1):\n",
    "            energies = []\n",
    "            for jdx in range(len(traj_dict[idx]['structure'])):  \n",
    "                ener = compute_binding_energy(paramset, traj_dict[idx]['structure'][jdx][0], traj_dict[idx]['structure'][jdx][1], lj_gen, numframe=720,cutoff=cutoff)\n",
    "                energies.append(ener.reshape((1,)))\n",
    "            energies = jnp.concatenate(energies)\n",
    "            weight = traj_dict[idx]['estimator'].estimate_weight(energies)\n",
    "            reweight_loading = traj_dict[idx]['loading'] * weight\n",
    "            error = jnp.power(jnp.average(reweight_loading)-traj_dict[idx]['experiment']['loading'],1)\n",
    "            errors.append(error.reshape((1,)))\n",
    "            #print(error)\n",
    "        errors = jnp.concatenate(errors)\n",
    "        return jnp.sum(errors)\n",
    "\n",
    "    v_and_g = jax.value_and_grad(loss, 0)\n",
    "    v, g = v_and_g(paramset)\n",
    "    \n",
    "    g.parameters['LennardJonesForce']['epsilon'] = g.parameters['LennardJonesForce']['epsilon']*scalar_epsilon\n",
    "    updates, opt_state = optimizer.update(g, opt_state)\n",
    "    updates.parameters = update_mask(updates.parameters,paramset.mask)\n",
    "    paramset = optax.apply_updates(paramset, updates)\n",
    "    paramset = jax.tree_map(lambda x: jnp.clip(x, 0.0, 1e8), paramset)\n",
    "    \n",
    "\n",
    "\n",
    "    update_ff(paramset)\n",
    "    lj_gen.overwrite(paramset)\n",
    "    sigma_indices, epsilon_indices = detect_parameter_change(paramset, paramset_old)\n",
    "    paramset = fix_changed_parameters(paramset, sigma_indices, epsilon_indices)\n",
    "    \n",
    "    print(\"Successfully update once\")\n",
    "    print(f\"This is {nloop}th time\", f\" Loss: {v} and Parameters: \",paramset.parameters['LennardJonesForce']['sigma'], paramset.parameters['LennardJonesForce']['epsilon'])\n",
    "    clear_backends()\n",
    "    clear_caches()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LennardJonesForce': {'epsilon': Array([-0.00501237, -0.00443108,  0.00425104, -0.00429429, -0.00455881,\n",
       "         -0.00427504], dtype=float64),\n",
       "  'epsilon_nbfix': Array([], dtype=float64),\n",
       "  'sigma': Array([-0.00500936, -0.00495903,  0.00501967,  0.00501423,  0.00501506,\n",
       "         -0.00501692], dtype=float64),\n",
       "  'sigma_nbfix': Array([], dtype=float64)}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_epsilon = paramset_old.parameters['LennardJonesForce']['epsilon']\n",
    "scalar_epsilon = scalar_epsilon/jnp.max(scalar_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1.        , 0.20791396, 0.08715755, 0.11856282, 0.31087106,\n",
       "       0.10622385], dtype=float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_and_g = jax.value_and_grad(loss, 0)\n",
    "v, g = v_and_g(paramset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dmff.api.paramset.ParamSet at 0x7f3aa07f7850>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g*scalar_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.parameters['LennardJonesForce']['epsilon'] = g.parameters['LennardJonesForce']['epsilon']*scalar_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates, opt_state = optimizer.update(g, opt_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
